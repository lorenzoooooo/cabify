{"cells":[{"cell_type":"markdown","metadata":{"id":"FCyot8tnZUKH"},"source":["Challenge 1\n","\n","Success measure criterion --> Impact of service to increase restaurant's customers\n","\n","Impact measure criterion:\n","    1. Compare sales before vs after picture posted\n","    3. Compare quality of home made pictures with pro pictures -- The gap has decreased due to improvements and availability of technology and free tutorials\n","    4. Since COVID more people order online --> Easier to sell food and then less need of high quality presentation? Or in the oder way higher standards?\n","    5. Evolution of maintenance cost for photografy service\n","\n","Implementation:\n","    Global:\n","        For each year from 2001 to 2023: Number of subs to the service / Number of subscription to just eat --> Regression for the next X years\n","        Evolution of the overall deployment and maintenance cost of the service --> regression for the next X years\n","    Sample of restaurants divided by geographical criterion (maybe target, type of food):\n","        Ratings (stars) of the service   \n","        Percentage of sell increase with respect to before\n","    Sample of customers divided by geographical criterion, target, type of food:\n","        Percentage of orders coming from restaurant using photo service\n","        Importance of picture criterion with respect to cost, qaulity and service criterion\n","\n","Avoid Bias by:\n","    Create balanced dataset -- Balance by geographical areas, by price range\n","    Normalization\n","    K-Folding??\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"IvfA0s_QZUKJ"},"source":["Punto 2: Semplice RNN con dataset etichettato.\n","\n","Etichettatura multipla --> Softmax come attivazione finale\n","\n","0: “Both are the same”\n","1: “They differ”\n","2: “I don’t know”\n","\n","Come gestire il fatto che lo stesso percorso possa essere etichettato in maniera differente da 2 o + persone? Devo trovare un criterio per scegliere quale etichetta tenere. (Qual'è l'etichetta con la percentuale maggiore sullo stesso percorso?)\n","\n","Attenzione real e estimated routes no hanno per forza la stessa lunghezza"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1PsKUB1ZUKJ","executionInfo":{"status":"ok","timestamp":1735648523011,"user_tz":-60,"elapsed":47102,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}},"outputId":"527df2d5-cbeb-4873-a01b-b3b5eedcfa93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/cabify\n","/content/drive/My Drive/cabify/cabify\n","Already up to date.\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/My\\ Drive/cabify\n","# with open(\"github_token.txt\", \"r\") as f:\n","#   token = f.read()\n","#  ! git clone https://{token}@github.com/lorenzoooooo/cabify\n","%cd cabify\n","! git pull\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"e965AdEGZUKK","executionInfo":{"status":"ok","timestamp":1735648530207,"user_tz":-60,"elapsed":7198,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import shutil\n","import random\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RxTbtPxmZUKK","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":8,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# #Load json to dataframe\n","# df = pd.read_json('challenge_dataset.json')\n","# print(f\"df size:  {df.size}\")\n","\n","# #Print a sample of real and estimated route\n","# i=df.iloc[3]\n","# df_estimated = pd.DataFrame(i['estimated_route'], columns=['Lat','Long'])\n","# # print(df_estimated.size)\n","# df_real = pd.DataFrame(i['real_route'], columns=['Lat','Long'])\n","# # print(df_real.size)\n","# plt.plot(df_estimated['Lat'], df_estimated['Long'], color='b')\n","# plt.plot(df_real['Lat'], df_real['Long'], color='r')\n","# # plt.scatter(df_estimated['Lat'], df_estimated['Long'], color='b')\n","# # plt.scatter(df_real['Lat'], df_real['Long'], color='r')\n","# plt.title('Annotator: ' + str(i['annotator'])+'\\n'+'Annotation: '+str(i['annotation']))\n","# plt.legend(['Estimated route','Real route'])"]},{"cell_type":"markdown","metadata":{"id":"fTBdxuldZUKK"},"source":["reflexions:\n","    1. Dataset samples have different sizes -- Input size is variable --> how to declare NN?\n","    2. Are points related temporally o spatially? RNN need equal temporal dependencies between samples. Otherwise can use Graph neural network.\n","\n","Approccio con feed forward:\n","Layer iniziale deve avere dimensione ingresso -- Basic MLP are not fit to take variable input size, either introduce padding or cut to fized size\n","\n","GNN/GCN approach: Can take variable graph sizes as input\n","\n","The point is that I don't have single graph with label, but couple of graphs. I don't want to learn how to recognize the \"ight\" graph, I want to recognize if the graph differs\n"]},{"cell_type":"markdown","metadata":{"id":"BL3aASQxZUKK"},"source":["Feed forward attempt"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3ZQvK8I4ZUKK","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":8,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# input_size=??\n","# number_of_features=2"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LqDXtEM0ZUKL","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":7,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# class Net(nn.Module):\n","\n","#     def __init__(self):\n","#         super(Net, self).__init__()\n","\n","#         # an affine operation: y = Wx + b\n","#         self.fc1 = nn.Linear(input_size, number_of_features )  # 5*5 from image dimension\n","#         self.fc2 = nn.Linear(120, 84)\n","#         self.fc3 = nn.Linear(84, 10)\n","\n","#     def forward(self, input):\n","#         f1 = F.relu(self.fc1(input))\n","#         # Fully connected layer F6: (N, 120) Tensor input,\n","#         # and outputs a (N, 84) Tensor, it uses RELU activation function\n","#         f2 = F.relu(self.fc2(f1))\n","#         # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n","#         # outputs a (N, 10) Tensor\n","#         output = self.fc3(f2)\n","#         return output\n","\n","\n","# net = Net()\n","# print(net)"]},{"cell_type":"markdown","metadata":{"id":"osblonFFZUKL"},"source":["\n","Possible alternative approach: Convolutional network --> Generate images of routes with associated labels and learn to recognize. 5000 images to generate -- Expensive approach"]},{"cell_type":"markdown","metadata":{"id":"A1l4VihcZUKL"},"source":["Generate fixed size image dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GdprCU8lZUKL","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":7,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# #Load dataset\n","# df = pd.read_json('challenge_dataset.json')\n","\n","# # print(f'number of same routes annotations: {df[(df[\"annotation\"]==\"Both are the same\")].shape[0]}')\n","# # print(f'number of different routes annotations: {df[(df[\"annotation\"]==\"They differ\")].shape[0]}')\n","\n","# #List containing final dataset composed of journey_id and annotation\n","# rows_to_keep = []\n","\n","# #Check if same route has multiple rating and if the annotations are different choose the one who is more rated\n","# iter = df['journey_id'].unique()\n","# for i in iter:\n","#     #Select all the rows regarding the same journey_id\n","#     mask=(df['journey_id']==i)\n","\n","#     #If this journey_id is rated only once append the journey_id and annotation to list\n","#     if (df[mask].shape[0]==1):\n","#         rows_to_keep.append([df[mask]['journey_id'].values[0], df[mask]['annotation'].values[0],\n","#                              df[mask]['estimated_route'].values[0], df[mask]['real_route'].values[0]])\n","\n","#     #Otherwise choose the more used annotation on this journey_id\n","#     else:\n","#         # Count the number of times an annotation appears\n","#         x=df[mask]\n","#         tmp=[]\n","#         tmp.append(x[(x['annotation']==\"Both are the same\")].shape[0])\n","#         tmp.append(x[(x['annotation']==\"They differ\")].shape[0])\n","#         tmp.append(x[(x['annotation']==\"I don't know\")].shape[0])\n","\n","#         #Select the annotation with max occurences\n","#         # selected_label=max(tmp)\n","#         idx_selected_label = tmp.index(max(tmp))\n","\n","#         # Map the index to the corresponding label\n","#         labels = [\"Both are the same\", \"They differ\", \"I don't know\"]\n","#         selected_label_value = labels[idx_selected_label]\n","\n","#         # Filter rows that match the selected label and append to list\n","#         tmp_list=x[x['annotation'] == selected_label_value].iloc[0]\n","#         rows_to_keep.append([tmp_list.values[0], tmp_list.values[2],\n","#                              tmp_list.values[3], tmp_list.values[4]])\n","\n","# labels_path='labels.csv'\n","# final_df=pd.DataFrame(rows_to_keep, columns=['journey_id', 'annotation', 'estimated_route', 'real_route'])\n","# final_df.to_csv(labels_path, columns=['journey_id', 'annotation'], index=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DPMEdLuFZUKL","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":7,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# # Create directory to save images\n","# output_dir = 'route_images'\n","# os.makedirs(output_dir, exist_ok=True)\n","\n","# # Turn interactive plotting off to not show every figure\n","# plt.ioff()\n","\n","# #Create database of unique routes images\n","# for _, df_sample in final_df.iterrows():\n","#     df_estimated = pd.DataFrame(df_sample['estimated_route'], columns=['Lat','Long'])\n","#     df_real = pd.DataFrame(df_sample['real_route'], columns=['Lat','Long'])\n","\n","#     fig = plt.figure(frameon=False)\n","#     # Set the figure size to be square (for example, 6x6 inches)\n","#     fig.set_size_inches(6, 6)\n","\n","#     image_path = f'{output_dir}/{df_sample[\"journey_id\"]}.png'\n","#     ax = plt.Axes(fig, [0., 0., 1., 1.])\n","#     ax.set_axis_off()\n","#     fig.add_axes(ax)\n","\n","#     plt.plot(df_estimated['Lat'], df_estimated['Long'], color='c')\n","#     plt.plot(df_real['Lat'], df_real['Long'], color='r')\n","#     # plt.savefig(image_path, dpi=300, bbox_inches='tight') # Dimension = 1920*1440 pixels\n","#     plt.savefig(image_path, dpi=37, bbox_inches='tight')   # Dimension 224*224\n","#     # plt.savefig(image_path, dpi=5, bbox_inches='tight')   # Dimension 32*32\n","#     plt.close()\n","\n","# #Execution time - 6min39s for image Dimension = 1920*1440 pixels\n","# #Execution time - 1min30s for image Dimension = 224*224 pixels\n","# #Execution time - 31s for image Dimension = 32*32 pixels"]},{"cell_type":"markdown","metadata":{"id":"rFb6k2I3ZUKL"},"source":["Create dataset splitting in Train, Val and Test - Unbalanced\n","----Run only once, oherwise it adds to the dataset previously created ---"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"3eCJNDAPZUKL","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":7,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# Paths\n","source_dir = 'route_images'\n","dataset_dir='dataset'\n","val_dir = f'{dataset_dir}/Val/'\n","train_dir = f'{dataset_dir}/Train/'\n","test_dir = f'{dataset_dir}/Test/'\n","output_dir = 'labels.csv'\n","# labels_list=['same','different','idk']\n","#For now i don't create the idk class\n","# labels_list=['same','different']\n","labels_list=['different','same']\n","dir_list=[train_dir, test_dir, val_dir]\n","\n","# Do the following only if the dataset has not been already created. To create new just empty the dataset folder\n","if len(os.listdir(dataset_dir)) == 0:\n","    #### Split Dataset equally between Train and Validation #############################################################\n","    for i in dir_list:\n","        if not os.path.exists(i):\n","            os.makedirs(i)\n","        for j in labels_list:\n","            path=f'{i}{j}'\n","            print(path)\n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","\n","    ## Import csv file containing labels and annotation and count the number of total elements\n","    labels = pd.read_csv(output_dir)\n","    num_files = len(labels)\n","    print('Numero di files nella cartella: ', num_files)\n","\n","\n","    # Create mask for each annotation\n","    mask_same = (labels['annotation']=='Both are the same')\n","    print(f'number of same elements: {len(labels[mask_same])}')\n","    mask_different = (labels['annotation']=='They differ')\n","    print(f'number of diff elements: {len(labels[mask_different])}')\n","    mask_idk=(labels['annotation']==\"I don't know\")\n","    print(f'number of idk elements: {len(labels[mask_idk])}')\n","\n","    #Divide between training, validation and test (70%,10%,20%) --- Not using label I don't know\n","    #Create Training set\n","    train_set=[]\n","    x=labels[mask_same]['journey_id'].to_list()\n","    y=labels[mask_different]['journey_id'].to_list()\n","    train_set = random.sample(x, int(0.70*len(x))) + random.sample(y, int(0.70*len(y)))\n","\n","    #Select the remaining data and split it between test (2/3) and validation set (1/3)\n","    # To apply the difference operator I hve to cast the data to set. I cast it back to list for random samples.\n","    remaining_x_set = set(x).difference(train_set)\n","    remaining_y_set = set(y).difference(train_set)\n","    test_set = (random.sample(list(remaining_x_set), int(0.66*len(remaining_x_set))) +\n","                random.sample(list(remaining_y_set), int(0.66*len(remaining_y_set))))\n","    val_set = set(list(remaining_x_set) + list(remaining_y_set)).difference(test_set)\n","\n","    #Copy images in the respective folder\n","    for i in labels.values:\n","        idx=i[1]\n","        files=i[0]\n","\n","        #Categorize data based on the labels\n","        if idx == 'Both are the same':\n","            folder=labels_list[0]\n","        elif idx == 'They differ':\n","            folder=labels_list[1]\n","        # else:\n","        #     folder=labels_list[2]\n","\n","        #Place data in the correct dataset spit (Train, Test, Validation)\n","        if files in train_set:\n","            shutil.copy(os.path.join(source_dir, files+'.png'), f'{train_dir}{folder}')\n","        elif files in test_set:\n","            shutil.copy(os.path.join(source_dir, files+'.png'), f'{test_dir}{folder}')\n","        elif files in val_set:\n","            shutil.copy(os.path.join(source_dir, files+'.png'), f'{val_dir}{folder}')\n","        else:\n","            continue"]},{"cell_type":"markdown","metadata":{"id":"tgdI1vvjZUKM"},"source":["size: 32*32"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OGI-PTBLZUKM","executionInfo":{"status":"ok","timestamp":1735648530208,"user_tz":-60,"elapsed":6,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["# class convNet32(nn.Module):\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.conv1 = nn.Conv2d(3, 6, 5)\n","#         self.pool = nn.MaxPool2d(2, 2)\n","#         self.conv2 = nn.Conv2d(6, 16, 5)\n","\n","#         # self.fc1 = nn.Linear(16 * 5 * 5, 120)  ## From the calculation on papaer it should be input dimension=16*10*10\n","#         self.fc1 = nn.Linear(16 * 10 * 10, 120)\n","#         self.fc2 = nn.Linear(120, 84)\n","#         self.fc3 = nn.Linear(84, 10)\n","\n","#     def forward(self, x):\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         x = self.pool(F.relu(self.conv2(x)))\n","#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.fc3(x)\n","#         return x"]},{"cell_type":"markdown","metadata":{"id":"WjG-NZiyZUKM"},"source":["size 224*224"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fzjahOTZUKM","executionInfo":{"status":"ok","timestamp":1735648538512,"user_tz":-60,"elapsed":8310,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}},"outputId":"9e865abf-18f4-4d55-eb8f-8f6f7258ed66"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleCNNconvNet224(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=200704, out_features=4096, bias=True)\n","  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",")\n"]}],"source":["class SimpleCNNconvNet224(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNNconvNet224, self).__init__()\n","\n","        # First convolution layer\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)  # Output: 224x224x64\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)      # Output: 112x112x64\n","\n","        # Second convolution layer\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Output: 112x112x128\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)       # Output: 56x56x128\n","\n","        # Third convolution layer\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1) # Output: 56x56x256\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)       # Output: 28x28x256\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(256 * 28 * 28, 4096)   # Flattened input to FC layer\n","        self.fc2 = nn.Linear(4096, 1024)             # Second FC layer\n","        self.fc3 = nn.Linear(1024, 2)               # Output layer (2 classes)\n","\n","    def forward(self, x):\n","        # Pass through first convolution and max pool\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        print(f'dimensione di x fopo conv1: {x.size()}')\n","        # Pass through second convolution and max pool\n","        x = F.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        print(f'dimensione di x fopo conv2: {x.size()}')\n","        # Pass through third convolution and max pool\n","        x = F.relu(self.conv3(x))\n","        x = self.pool3(x)\n","        print(f'dimensione di x fopo conv3: {x.size()}')\n","        # Flatten the output for the fully connected layers\n","        # x = x.view(-1, 256 * 28 * 28)\n","        x=torch.flatten(x,1)\n","\n","        # Pass through fully connected layers\n","        x = F.relu(self.fc1(x))\n","        print(f'dimensione di x fopo fc1: {x.size()}')\n","        x = F.relu(self.fc2(x))\n","        print(f'dimensione di x fopo fc2: {x.size()}')\n","        x = self.fc3(x)\n","        print(f'dimensione di x fopo fc3: {x.size()}')\n","        return x\n","\n","print(SimpleCNNconvNet224())"]},{"cell_type":"markdown","metadata":{"id":"E5QbfvA0ZUKM"},"source":["Delcare hyperparameters, choose optimizer, determine if it's possible to use cpu or gpu, and load dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLblgq2RZUKN","executionInfo":{"status":"ok","timestamp":1735649308280,"user_tz":-60,"elapsed":5777,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}},"outputId":"b9af0e4e-8727-40c7-c1a6-bfffe426e080"},"outputs":[{"output_type":"stream","name":"stdout","text":["dataset/Train/\n","\n","Batch 1:\n","Images shape:  torch.Size([10, 3, 224, 224])\n","Batch 2:\n","Images shape:  torch.Size([10, 3, 224, 224])\n","Batch 3:\n","Images shape:  torch.Size([10, 3, 224, 224])\n","dataset/Val/\n","\n","Batch 1:\n","Images shape:  torch.Size([10, 3, 224, 224])\n","Batch 2:\n","Images shape:  torch.Size([10, 3, 224, 224])\n","Batch 3:\n","Images shape:  torch.Size([10, 3, 224, 224])\n"]}],"source":["from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import Compose, ToTensor, Grayscale, CenterCrop\n","import argparse\n","import torch.nn.functional as F\n","import torch.nn\n","from torch.optim import Adam\n","import torch\n","from datetime import datetime\n","\n","# Function to transform image\n","def create_datagen(data_dir, batch_size=8):\n","    # transform = Compose([Grayscale(), ToTensor()])    # for bn images\n","    transform = Compose([ToTensor(), CenterCrop([224,224]),\n","                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])   # input: [224*224]\n","    dataset = ImageFolder(data_dir, transform=transform)\n","    dataloader = DataLoader(dataset,\n","                            batch_size=batch_size,\n","                            shuffle=True,\n","                            num_workers=2)\n","    return dataloader\n","\n","def dataset_description(data_loader):\n","    print(data_loader.dataset.root)\n","    print()  # Add an empty line for better readability\n","    for batch_idx, (images, _) in enumerate(data_loader):\n","        print(f\"Batch {batch_idx+1}:\")\n","        print(\"Images shape: \", images.size())  # Prints shape of the batch of images\n","\n","        # Optionally, you can break after printing a few batches\n","        if batch_idx == 2:\n","            break\n","\n","parameters = {'train_dir': train_dir,\n","                'val_dir': val_dir,\n","                'log_interval': 2,\n","                'epochs': 10,\n","                'train_batch_size': 10,\n","                'val_batch_size': 10,\n","                'log_dir': f'tensorboard/logs_{datetime.now().strftime(\"%d%m%Y_%H-%M\")}',\n","                'save_graph': True,\n","                'load_weight_path': None\n","                }\n","\n","train_loader = create_datagen(parameters['train_dir'], parameters['train_batch_size'])\n","dataset_description(train_loader)\n","val_loader = create_datagen(parameters['val_dir'], parameters['val_batch_size'])\n","dataset_description(val_loader)"]},{"cell_type":"markdown","metadata":{"id":"sXeQRAmaZUKN"},"source":["Show single mini-batch"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"uDjN0lslZUKN","executionInfo":{"status":"ok","timestamp":1735648562777,"user_tz":-60,"elapsed":3398,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}},"outputId":"4061c9fc-910b-4ec2-eae5-b3d504805e20"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["different same  same  different same  different different different same  same \n"]}],"source":["def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","classes=tuple(labels_list)\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","imshow(torchvision.utils.make_grid(images))\n","\n","#Sono invertiti le label rispetto alle immmagini?\n","print(' '.join(f'{classes[labels[j]]:5s}' for j in range(parameters['train_batch_size'])))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1bPG_P5ZUKN","executionInfo":{"status":"ok","timestamp":1735649552717,"user_tz":-60,"elapsed":5133,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}},"outputId":"e96be67a-b661-47f4-821e-34f9e3d115f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.5.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (3.0.2)\n"]}],"source":["!pip install pytorch-ignite\n","from ignite.engine import Engine, Events\n","from ignite.metrics import Loss, RunningAverage\n","from ignite.metrics import ConfusionMatrix\n","# from torch.utils.tensorboard import SummaryWriter\n","import pathlib\n","from torchvision import datasets, transforms\n","import torch\n","from ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine\n","import os\n","\n","\n","def create_summary_writer(model, train_loader, log_dir, save_graph, device):\n","    \"\"\"Creates a tensorboard summary writer\n","\n","    Arguments:\n","        model {pytorch model}     -- the model whose graph needs to be saved\n","        train_loader {dataloader} -- the training dataloader\n","        log_dir {str}             -- the logging directory path\n","        save_graph {bool}         -- if True a graph is saved into the\n","                                     tensorboard log folder\n","        device {torch.device}     -- torch device object\n","\n","    Returns:\n","        writer -- tensorboard SummaryWriter object\n","    \"\"\"\n","    # writer = SummaryWriter(log_dir=log_dir)\n","    # if save_graph:\n","    #     images, labels = next(iter(train_loader))\n","    #     images = images.to(device)\n","    #     try:\n","    #         writer.add_graph(model, images)\n","    #     except Exception as e:\n","    #         print(\"Failed to save model graph: {}\".format(e))\n","    # return writer\n","\n","def train(model, optimizer, loss_fn, train_loader, val_loader,\n","          log_dir, device, epochs, log_interval,\n","          load_weight_path=None, save_graph=False):\n","    \"\"\"Training logic for the wavelet model\n","\n","    Arguments:\n","        model {pytorch model}       -- the model to be trained\n","        optimizer {torch optim}     -- optimiser to be used\n","        loss_fn                     -- loss_fn function\n","        train_loader {dataloader}   -- training dataloader\n","        val_loader {dataloader}     -- validation dataloader\n","        log_dir {str}               -- the log directory\n","        device {torch.device}       -- the device to be used e.g. cpu or cuda\n","        epochs {int}                -- the number of epochs\n","        log_interval {int}          -- the log interval for train batch loss\n","\n","    Keyword Arguments:\n","        load_weight_path {str} -- Model weight path to be loaded (default: {None})\n","        save_graph {bool}      -- whether to save the model graph (default: {False})\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    model.to(device)\n","    if load_weight_path is not None:\n","        model.load_state_dict(torch.load(load_weight_path))\n","\n","    optimizer = optimizer(model.parameters())\n","\n","    #training steps\n","    def process_function(engine, batch):\n","        model.train()\n","        optimizer.zero_grad()\n","        x, labels = batch\n","        x = x.to(device)\n","        print(x.size())\n","        y = model(x)\n","        labels = labels.to(device)\n","        loss = loss_fn(y, labels)\n","        loss.backward()\n","        optimizer.step()\n","        return loss.item()\n","\n","    # evaluation steps (Val)\n","    def evaluate_function(engine, batch):\n","        model.eval()\n","        with torch.no_grad():\n","            x, labels = batch\n","            x = x.to(device)\n","            y = model(x)\n","            labels=labels.to(device)\n","            loss = loss_fn(y,labels)\n","            return loss.item()\n","\n","    # Questo oggetto contiene tutti i dati riguardanti il training\n","    trainer = Engine(process_function)\n","    # Questo oggetto contiene tutti i dati riguardanti la valutazione del modello. Ogni volta che viene chimato run su un determinato dataset\n","    # il modello viene valutato.\n","    # #Calcola la loss e segna ilnumero di epoche correnti, l'iterazione etc...\n","    evaluator = Engine(evaluate_function)\n","\n","    RunningAverage(output_transform=lambda x:x).attach(trainer,'loss')\n","    RunningAverage(output_transform=lambda x:x).attach(evaluator,'loss')\n","\n","\n","    # writer = create_summary_writer(model, train_loader, log_dir,\n","    #                                save_graph, device)\n","\n","    def score_function(engine):\n","        return -engine.state.metrics['loss']\n","\n","    to_save = {'model': model}\n","    handler = Checkpoint(\n","        to_save,\n","        DiskSaver(os.path.join(log_dir, 'models'), create_dir=True),\n","        n_saved=5, filename_prefix='best', score_function=score_function,\n","        score_name=\"loss\",\n","        global_step_transform=global_step_from_engine(trainer))\n","\n","    evaluator.add_event_handler(Events.COMPLETED, handler)\n","\n","    # Calcola la loss ogni \"log_interval\" iterazioni sul batch corrente. \"log interval\" di default vale 10.\n","    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n","    def log_training_loss(engine):\n","        print(\n","            f\"Epoch[{engine.state.epoch}] Iteration[{engine.state.iteration}/\"\n","            f\"{len(train_loader)}] Loss: {engine.state.output:.10f}\"\n","        )\n","        # writer.add_scalar(\"training/loss\", engine.state.output,\n","        #                   engine.state.iteration)\n","\n","    # Calcola la loss su tutto il training set una volta che l'epoca è finita\n","    @trainer.on(Events.EPOCH_COMPLETED)\n","    def log_training_results(engine):\n","        evaluator.run(train_loader)\n","        metrics = evaluator.state.metrics\n","        avg_loss = metrics[\"loss\"]\n","        print(\n","            f\"Training Results - Epoch: {engine.state.epoch} Avg loss: {avg_loss:.10f}\"\n","        )\n","        # writer.add_scalar(\"training/avg_loss\", avg_loss, engine.state.epoch)\n","\n","    # Calcola la loss su tutto il validation set una volta che l'epoca è finita\n","    @trainer.on(Events.EPOCH_COMPLETED)\n","    def log_validation_results(engine):\n","        evaluator.run(val_loader)\n","        metrics = evaluator.state.metrics\n","        avg_loss = metrics[\"loss\"]\n","\n","        print(\n","            f\"Validation Results - Epoch: {engine.state.epoch} Avg loss: {avg_loss:.10f}\"\n","        )\n","        # writer.add_scalar(\"validation/avg_loss\", avg_loss, engine.state.epoch)\n","\n","    trainer.run(train_loader, max_epochs=epochs)\n","\n","    # writer.close()"]},{"cell_type":"markdown","metadata":{"id":"u_XayXFLZUKN"},"source":["trainer"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"kzdNf0WjZUKN","executionInfo":{"status":"ok","timestamp":1735649575601,"user_tz":-60,"elapsed":6754,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[],"source":["optimizer = Adam\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","loss = F.cross_entropy\n","model=SimpleCNNconvNet224()\n","\n","# model.to(device)\n","# optimizer = optimizer(model.parameters())"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"naREcLCFZUKN","outputId":"c697d7f9-357c-40dc-8ccb-a3118b708512","colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"status":"error","timestamp":1735649578932,"user_tz":-60,"elapsed":1743,"user":{"displayName":"lorenzo giraldi","userId":"10228983639254068753"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 3, 224, 224])\n","dimensione di x fopo conv1: torch.Size([10, 64, 112, 112])\n","dimensione di x fopo conv2: torch.Size([10, 128, 56, 56])\n","dimensione di x fopo conv3: torch.Size([10, 256, 28, 28])\n","dimensione di x fopo fc1: torch.Size([10, 4096])\n","dimensione di x fopo fc2: torch.Size([10, 1024])\n","dimensione di x fopo fc3: torch.Size([10, 2])\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.23 GiB is free. Process 13265 has 13.52 GiB memory in use. Of the allocated memory 13.09 GiB is allocated by PyTorch, and 298.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.23 GiB is free. Process 13265 has 13.52 GiB memory in use. Of the allocated memory 13.09 GiB is allocated by PyTorch, and 298.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.23 GiB is free. Process 13265 has 13.52 GiB memory in use. Of the allocated memory 13.09 GiB is allocated by PyTorch, and 298.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-2af81ec350a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(model, optimizer, loss, train_loader,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_interval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           parameters['load_weight_path'], parameters['save_graph'])\n","\u001b[0;32m<ipython-input-25-6d6b7d24f208>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, train_loader, val_loader, log_dir, device, epochs, log_interval, load_weight_path, save_graph)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# writer.add_scalar(\"validation/avg_loss\", avg_loss, engine.state.epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# writer.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterrupt_resume_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    954\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                     \u001b[0mepoch_time_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                     \u001b[0;31m# time is available for handlers but must be updated after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_terminate_or_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_terminate_or_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-6d6b7d24f208>\u001b[0m in \u001b[0;36mprocess_function\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             has_complex = self._init_group(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    151\u001b[0m                     )\n\u001b[1;32m    152\u001b[0m                     \u001b[0;31m# Exponential moving average of gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                     state[\"exp_avg\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    154\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     )\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.23 GiB is free. Process 13265 has 13.52 GiB memory in use. Of the allocated memory 13.09 GiB is allocated by PyTorch, and 298.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["train(model, optimizer, loss, train_loader,\n","          val_loader, parameters['log_dir'], device, parameters['epochs'],\n","          parameters['log_interval'],\n","          parameters['load_weight_path'], parameters['save_graph'])"]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Use of cross entropy loss and consequent update of process_function and evaluation_function\"\n","!git config --global user.email \"giraldilorenzo63@gmail.com\"\n","!git config --global user.name \"lorenzoooooo\"\n","!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7_EqdIcyEY6","outputId":"fcf02555-910a-462a-ebfb-972516617e51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@0ad05bad3b5a.(none)')\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}